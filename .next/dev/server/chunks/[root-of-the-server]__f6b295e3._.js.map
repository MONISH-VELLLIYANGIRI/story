{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 34, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/MONISH%20V/Downloads/story/app/api/generate-story/route.ts"],"sourcesContent":["\ninterface StoryRequest {\n  prompt: string;\n  genre: string;\n  characters?: string;\n}\n\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n  apiKey: \"ollama\", // dummy value (required by SDK)\n  baseURL: \"http://localhost:11434/v1\",\n});\n\nconst MODEL = \"llama3.1:8b\";\n\n\nasync function generateStory(systemPrompt: string, userPrompt: string) {\n  const response = await client.chat.completions.create({\n    model: MODEL,\n    messages: [\n      {\n        role: \"system\",\n        content: systemPrompt,\n      },\n      {\n        role: \"user\",\n        content: userPrompt,\n      },\n    ],\n    temperature: 0.8,\n    max_tokens: 800,\n  });\n\n  const text = response.choices?.[0]?.message?.content;\n\n  if (!text) {\n    throw new Error(\"No text returned from Gemini model\");\n  }\n\n  return text;\n}\n\nexport async function POST(request: Request) {\n  try {\n    const { prompt, genre, characters }: StoryRequest = await request.json();\n\n    if (!prompt?.trim()) {\n      return Response.json({ error: \"Story theme is required\" }, { status: 400 });\n    }\n\n    if (!genre?.trim()) {\n      return Response.json({ error: \"Genre is required\" }, { status: 400 });\n    }\n\n    const systemPrompt = `You are a creative storyteller specializing in ${genre}.\nWrite a vivid, emotional, and well-structured story outline.`;\n\n    const userPrompt = `\nGenre: ${genre}\n${characters ? `Main Characters: ${characters}` : \"Create original characters\"}\nTheme: ${prompt}\n\nGenerate a detailed and creative story plot.\n`;\n\n    const plot = await generateStory(systemPrompt, userPrompt);\n\n    return Response.json({\n      plot,\n      metadata: {\n        genre,\n        hasCustomCharacters: !!characters,\n        model: MODEL,\n        generatedAt: new Date().toISOString(),\n      },\n    });\n  } catch (error: any) {\n    console.error(\"Story Generation Error:\", error);\n    return Response.json(\n      { error: error.message || \"Failed to generate story\" },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET() {\n  return Response.json({\n    message: \"Story Generator API (Gemini 2.5 Flash via OpenAI-compatible endpoint)\",\n    model: MODEL,\n  });\n}\n"],"names":[],"mappings":";;;;;;AAOA;AAAA;;AAEA,MAAM,SAAS,IAAI,mLAAM,CAAC;IACxB,QAAQ;IACR,SAAS;AACX;AAEA,MAAM,QAAQ;AAGd,eAAe,cAAc,YAAoB,EAAE,UAAkB;IACnE,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;QACpD,OAAO;QACP,UAAU;YACR;gBACE,MAAM;gBACN,SAAS;YACX;YACA;gBACE,MAAM;gBACN,SAAS;YACX;SACD;QACD,aAAa;QACb,YAAY;IACd;IAEA,MAAM,OAAO,SAAS,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS;IAE7C,IAAI,CAAC,MAAM;QACT,MAAM,IAAI,MAAM;IAClB;IAEA,OAAO;AACT;AAEO,eAAe,KAAK,OAAgB;IACzC,IAAI;QACF,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,GAAiB,MAAM,QAAQ,IAAI;QAEtE,IAAI,CAAC,QAAQ,QAAQ;YACnB,OAAO,SAAS,IAAI,CAAC;gBAAE,OAAO;YAA0B,GAAG;gBAAE,QAAQ;YAAI;QAC3E;QAEA,IAAI,CAAC,OAAO,QAAQ;YAClB,OAAO,SAAS,IAAI,CAAC;gBAAE,OAAO;YAAoB,GAAG;gBAAE,QAAQ;YAAI;QACrE;QAEA,MAAM,eAAe,CAAC,+CAA+C,EAAE,MAAM;4DACrB,CAAC;QAEzD,MAAM,aAAa,CAAC;OACjB,EAAE,MAAM;AACf,EAAE,aAAa,CAAC,iBAAiB,EAAE,YAAY,GAAG,6BAA6B;OACxE,EAAE,OAAO;;;AAGhB,CAAC;QAEG,MAAM,OAAO,MAAM,cAAc,cAAc;QAE/C,OAAO,SAAS,IAAI,CAAC;YACnB;YACA,UAAU;gBACR;gBACA,qBAAqB,CAAC,CAAC;gBACvB,OAAO;gBACP,aAAa,IAAI,OAAO,WAAW;YACrC;QACF;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,SAAS,IAAI,CAClB;YAAE,OAAO,MAAM,OAAO,IAAI;QAA2B,GACrD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe;IACpB,OAAO,SAAS,IAAI,CAAC;QACnB,SAAS;QACT,OAAO;IACT;AACF","debugId":null}}]
}